import cv2
import numpy as np
from PIL import Image, ImageDraw, ImageEnhance, ImageFilter, ImageChops
from dataclasses import dataclass
from enum import Enum
import pytesseract
from core import ocr
from typing import Tuple, Optional, List
from core.region_match import MatchResult, ShapeResult, MatchShape
from functools import wraps

pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'


def find_subimage(parent: Image.Image,
                  template: Image.Image,
                  min_scale: float = 1,
                  max_scale: float = 1,
                  scale_step: float = 0.1,
                  method=cv2.TM_CCORR_NORMED
                  ) -> MatchResult:
    """
    Search `parent` for the best match to `template`, ignoring transparent pixels
    and trying scales from min_scale to max_scale in increments of scale_step.
    Returns the MatchResult at the scale & location with highest confidence.
    """
    # --- prepare parent image as BGR ---
    parent_rgba = np.array(parent.convert("RGBA"))
    parent_bgr  = cv2.cvtColor(parent_rgba, cv2.COLOR_RGBA2BGR)

    # --- prepare template + mask from its alpha channel ---
    tpl_rgba = np.array(template.convert("RGBA"))
    tpl_bgr  = cv2.cvtColor(tpl_rgba, cv2.COLOR_RGBA2BGR)
    tpl_mask = tpl_rgba[:, :, 3]  # alpha channel: 0 = transparent, 255 = opaque

    best = MatchResult(0, 0, 0, 0, confidence=-1.0, scale=1.0)
    parent_h, parent_w = parent_bgr.shape[:2]

    # loop over scales
    scale = min_scale
    while scale <= max_scale + 1e-6:
        # compute new size
        w = int(tpl_bgr.shape[1] * scale)
        h = int(tpl_bgr.shape[0] * scale)
        # skip if template is larger than parent
        if 1 < w < parent_w and 1 < h < parent_h:
            resized_tpl  = cv2.resize(tpl_bgr, (w, h),
                                      interpolation=cv2.INTER_AREA if scale < 1.0 else cv2.INTER_CUBIC)
            resized_mask = cv2.resize(tpl_mask, (w, h), interpolation=cv2.INTER_NEAREST)

            # matchTemplate with mask (only works for SQDIFF or CCORR_NORMED)
            result = cv2.matchTemplate(parent_bgr,
                                       resized_tpl,
                                       method,
                                       mask=resized_mask)
            
            result = np.nan_to_num(result, nan=-1.0, posinf=-1.0, neginf=-1.0)

            # get best match
            min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)
            if method in (cv2.TM_CCORR_NORMED, cv2.TM_CCOEFF_NORMED):
                confidence = max_val
                top_left   = max_loc
            else:
                # TM_SQDIFF variants: lower = better, so invert
                confidence = 1.0 - min_val
                top_left   = min_loc
                
            if confidence > best.confidence:
                best = MatchResult(
                    start_x=top_left[0],
                    start_y=top_left[1],
                    end_x=top_left[0] + w,
                    end_y=top_left[1] + h,
                    confidence=confidence,
                    scale=scale
                )

        scale += scale_step

    if best.confidence < 0:
        raise ValueError("No valid match found (template never fit inside parent).")

    return best

def find_subimages(
    parent: Image.Image,
    template: Image.Image,
    min_scale: float = 1,
    max_scale: float = 1,
    scale_step: float = 0.1,
    method=cv2.TM_CCORR_NORMED,
    min_confidence: float = 0.5,
) -> List[MatchResult]:
    answers = []
    parent = parent.copy()
    m = find_subimage(
        parent=parent,
        template=template,
        min_scale=min_scale,
        max_scale=max_scale,
        scale_step=scale_step,
        method=method
    )
    while m.confidence >= min_confidence:
        answers.append(m)
        # remove the found match from the parent image
        parent = m.remove_from(parent)
        # find the next match in the updated parent image
        m = find_subimage(
            parent=parent,
            template=template,
            min_scale=min_scale,
            max_scale=max_scale,
            scale_step=scale_step,
            method=method
        )
    return answers


def mask_colors(
        image: Image.Image, 
        colors: List[Tuple[int, int, int]], 
        tolerance: int = 30
    ) -> Image.Image:
    """
    Create a mask for the specified colors in the image.
    The mask will be a new image where pixels matching the specified colors
    are set to white, and all other pixels are set to black.
    """
    mask = Image.new("L", image.size, 0)  # Create a black mask

    for color in colors:
        # Create a color range for the mask
        r, g, b = color
        lower_bound = (max(0, r - tolerance), max(0, g - tolerance), max(0, b - tolerance))
        upper_bound = (min(255, r + tolerance), min(255, g + tolerance), min(255, b + tolerance))

        # Create a temporary image to find the matching pixels
        temp_image = image.convert("RGB")
        temp_mask = Image.new("L", image.size, 0)

        for x in range(temp_image.width):
            for y in range(temp_image.height):
                pixel = temp_image.getpixel((x, y))
                if (lower_bound[0] <= pixel[0] <= upper_bound[0] and
                    lower_bound[1] <= pixel[1] <= upper_bound[1] and
                    lower_bound[2] <= pixel[2] <= upper_bound[2]):
                    temp_mask.putpixel((x, y), 255)

        # Combine the temporary mask with the main mask for each color
        mask = ImageChops.lighter(mask, temp_mask)
    return mask.convert("L")  # Convert to binary mask (black and white)
    





def write_text_to_image(image: Image, text: str, font_size: int = 20, color="black") -> Image.Image:

    # Load a default font with the specified size
    try:
        font = ImageFont.truetype("arial.ttf", font_size)
    except IOError:
        font = ImageFont.load_default()

    # Calculate text dimensions
    text_width = font.getlength(text)
    new_width = max(image.width, text_width + 20)
    new_height = image.height + font_size + 20
    new_image = Image.new("RGBA", (int(new_width), int(new_height)), (255, 255, 255, 0))

    # Paste the original image onto the new image
    new_image.paste(image, (0, 0))

    # Write the text below the original image
    draw = ImageDraw.Draw(new_image)
    text_x = (new_width - text_width) // 2
    text_y = image.height + 10
    draw.text((text_x, text_y), text, fill=color, font=font)

    return new_image

def draw_box_on_image(image: Image, match: MatchResult, padding_x=0, padding_y=0, box_color="green") -> Image.Image:

    # Apply padding
    start_x = max(0, match.start_x - padding_x)
    start_y = max(0, match.start_y - padding_y)
    end_x = min(image.width, match.end_x + padding_x)
    end_y = min(image.height, match.end_y + padding_y)

    # Draw rectangle
    draw = ImageDraw.Draw(image)
    draw.rectangle([start_x, start_y, end_x, end_y], outline=box_color, width=2)

    return image

def draw_circle_on_image(image: Image, match: MatchResult, padding_x=0, padding_y=0, box_color="green") -> Image.Image:

    # Apply padding
    start_x = max(0, match.start_x - padding_x)
    start_y = max(0, match.start_y - padding_y)
    end_x = min(image.width, match.end_x + padding_x)
    end_y = min(image.height, match.end_y + padding_y)

    # Draw rectangle
    draw = ImageDraw.Draw(image)
    draw.circle([start_x, start_y, end_x, end_y], outline=box_color, width=2)

    return image

# ── helper to order cv2.boxPoints result TL‑TR‑BR‑BL ───────────────────
def _order_box(pts: np.ndarray) -> list[tuple[int, int]]:
    # sort by y (row) then x (col)
    pts = pts[np.lexsort((pts[:, 0], pts[:, 1]))]      # top 2 then bottom 2
    tl, tr = sorted(pts[:2], key=lambda p: p[0])       # left‑most is TL
    bl, br = sorted(pts[2:], key=lambda p: p[0])       # left‑most is BL
    return [tuple(tl), tuple(tr), tuple(br), tuple(bl)]

# ───────────────────────────────────────────────────────────────────────
def find_color_box(
    pil_img: Image.Image,
    target_rgb: Tuple[int, int, int],
    tol: int = 40,
) -> ShapeResult:
    """
    Locate the largest rectangular outline drawn in `target_rgb` (± `tol`)
    and return a ShapeResult whose four vertices sit *inside* that border.
    Works for both axis‑aligned and rotated rectangles.
    """
    # 1. colour mask ────────────────────────────────────────────────────
    arr = np.asarray(pil_img.convert("RGB"))
    diff = np.abs(arr - np.array(target_rgb))
    mask = np.all(diff <= tol, axis=2) if tol else np.all(arr == target_rgb, axis=2)

    # 2. connected components – grab largest blob ──────────────────────
    num, labels = cv2.connectedComponents(mask.astype(np.uint8), connectivity=4)
    if num <= 1:
        raise ValueError("No pixels found with the specified colour.")

    best_area, coords_best = -1, None
    for lbl in range(1, num):
        coords = np.column_stack(np.where(labels == lbl))
        if coords.shape[0] > best_area:
            best_area, coords_best = coords.shape[0], coords

    rows, cols = coords_best[:, 0], coords_best[:, 1]
    top, bottom = rows.min(), rows.max()
    left, right = cols.min(), cols.max()
    h, w = bottom - top, right - left

    # 3. decide: on‑axis or rotated? ────────────────────────────────────
    # a narrow blob (thickness 1‑3 px) with very thin diagonals means axis‑aligned
    # 3. decide: on‑axis or rotated? ────────────────────────────────────
    if h == 0 or w == 0:
        raise ValueError("Degenerate box.")

    axis_ratio = min(h, w) / max(h, w)
    if axis_ratio < 0.05:
        axis_ratio = 0

    # replace this line ↓
    # filled = cv2.countNonZero(mask[top:bottom+1, left:right+1])
    filled = np.count_nonzero(mask[top:bottom + 1, left:right + 1])

    # is_axis_aligned = (
    #     axis_ratio < 0.2 or            # very thin outline
    #     filled >= 0.9 * best_area
    # )

    # if is_axis_aligned:
    #     # 4A. simple axis‑aligned path (unchanged except defaults) ───────
    #     left_in, right_in = (left + 1, right - 1) if w > 2 else (left, right)
    #     top_in, bottom_in = (top + 1, bottom - 1) if h > 2 else (top, bottom)
    #     pts = [
    #         (left_in,  top_in),
    #         (right_in, top_in),
    #         (right_in, bottom_in),
    #         (left_in,  bottom_in),
    #     ]
    #     expected_perim = 2 * (w + h)
    #     confidence = best_area / max(expected_perim, 1)
    #     return ShapeResult(points=pts, confidence=confidence)

    # 4B. rotated rectangle path ────────────────────────────────────────
    # OpenCV wants (x, y) not (row, col)
    pts_xy = np.flip(coords_best, axis=1).astype(np.float32)
    rect = cv2.minAreaRect(pts_xy)               # (cx,cy), (w,h), angle
    box = cv2.boxPoints(rect)                    # 4×2 float
    box = np.int32(box)

    # nudge each vertex 1 px toward the centre so it sits *inside* outline
    centre = np.mean(box, axis=0)
    vecs = centre - box
    norms = np.linalg.norm(vecs, axis=1, keepdims=True)
    norms[norms == 0] = 1                        # avoid div‑by‑0
    box_in = (box + (vecs / norms)).astype(int)  # pull 1 px inward
    ordered = _order_box(box_in)

    # confidence ≈ blob area ÷ box perimeter (works for rotated too)
    w_rot, h_rot = rect[1]
    expected_perim = 2 * (w_rot + h_rot)
    confidence = best_area / max(expected_perim, 1)

    return ShapeResult(points=ordered, confidence=confidence)


from functools import wraps
import time
import inspect
from PIL import ImageFont


def timeit(func):
    """Improved decorator that shows ClassName.method only when the call
    truly originates from that class (instance or @classmethod)."""
    qual_parts = func.__qualname__.split(".")
    cls_name   = qual_parts[-2] if len(qual_parts) > 1 else None
    cls_obj    = None                     # resolved lazily

    @wraps(func)
    def wrapper(*args, **kwargs):
        nonlocal cls_obj

        # Resolve the class object the first time we actually get called
        if cls_obj is None and cls_name:
            mod = inspect.getmodule(func)
            cls_obj = getattr(mod, cls_name, None)

        start = time.time()
        try:
            return func(*args, **kwargs)
        finally:
            dur   = time.time() - start
            first = args[0] if args else None

            if cls_obj and first is not None and (first is cls_obj or isinstance(first, cls_obj)):
                label = f"{cls_name}.{func.__name__}"
            else:
                label = func.__name__

            # print(f"{label} took {dur:.4f} s")

    return wrapper

def seconds_to_hms(total_seconds: float | int) -> str:
    """
    Convert seconds → `HH:MM:SS` (hours may exceed 24 if you like).

    Examples
    --------
    >>> seconds_to_hms(3661)
    '01:01:01'
    >>> seconds_to_hms(98765.4)
    '27:26:05'
    """
    # Round to nearest second (change to int(total_seconds) for simple truncation)
    total_seconds = int(round(total_seconds))

    hours, remainder = divmod(total_seconds, 3600)
    minutes, seconds = divmod(remainder, 60)

    return f"{hours:02}:{minutes:02}:{seconds:02}"